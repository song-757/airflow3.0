import datetime
import pendulum
from airflow import DAG

from airflow.providers.standard.operators.python import PythonOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

with DAG(
    dag_id="dags_python_with_postgres_hook_bulk_load",
    schedule="30 6 * * *",
    start_date=pendulum.datetime(2025, 6, 24, tz="Asia/Seoul"),
    catchup=False,
    dagrun_timeout=datetime.timedelta(minutes=60),
) as dag:
    def insert_postgress(postgres_conn_id,tbl_nm,**kwargs):
        postgres_hook = PostgresHook(postgres_conn_id)
        postgres_hook.bulk_load(tbl_nm, file_nm)

        

    insert_postgress_hook_bulk_load = PythonOperator(
        task_id ='insert_postgress_hook_bulk_load',
        python_callable= insert_postgress,
        op_kwargs={
            'postgres_conn_id': 'conn-db-postgres-custom'
            ,'tbl_nm':'Tbcorona19CountStatus_bulk1'
            ,'file_nm':'/opt/airflow/files/TbCorona19CountStatus/{{data_interval_end.in_timezone("Asia/Seoul") | ds_nodash}}'
        } 
    )


    insert_postgress_hook_bulk_load